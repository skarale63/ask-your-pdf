{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89261c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.llms import Ollama\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1e4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set goofle api key in os.env \n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\") \n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")  \n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")  \n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] =  GOOGLE_API_KEY\n",
    "os.environ['LANGCHAIN_API_KEY'] =  LANGCHAIN_API_KEY\n",
    "os.environ['LANGCHAIN_PROJECT'] =  LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c24dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading PDF file from resources \n",
    "file_path = Path(r\"D:\\SHUBHAM\\git_repo\\ask-your-pdf\\resources\\Shubham_Karale_DS_2025_v1.pdf\")\n",
    "pdf_reader= PdfReader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d4abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shubham Karale \n",
      "Data Scientist \n",
      "Experienced Data Scientist with \n",
      "7 years of experience\n",
      ", including \n",
      "3 years specializing in Data Science & MLOps\n",
      ".\n",
      "Currently at \n",
      "Capgemini\n",
      ", optimizing ML models and \n",
      "migrating SAS-based ETL pipelines to PySpark\n",
      ", reducing model\n",
      "inference time by \n",
      "30%\n",
      " and improving accuracy by \n",
      "15%\n",
      ". Proﬁcient in \n",
      "Python, PySpark, Jenkins, Cloudera, AWS, and\n",
      "ML model testing\n",
      ". Strong expertise in \n",
      "feature engineering, hyperparameter tuning, cloud deployment, and\n",
      "MLOps pipelines\n",
      ". Seeking to leverage expertise in data-driven solutions and cloud-based machine learning. \n",
      "skarale63@gmail.com \n",
      "+91 96896 49778 \n",
      "pune, India \n",
      "linkedin.com/in/shubham-karale-b343a7221 \n",
      "WORK EXPERIENCE \n",
      "Data Scientist \n",
      "Capgemini Technology Services India Limited \n",
      "05/2024 - Present\n",
      ", \n",
      " \n",
      "Migrated \n",
      "SAS-based data pipelines\n",
      " to \n",
      "PySpark\n",
      ", optimizing data extraction for ML\n",
      "models. \n",
      "Extracted only relevant features\n",
      " from legacy SAS pipelines, reducing model\n",
      "inference time by \n",
      "30%\n",
      " and improving accuracy by \n",
      "15%\n",
      ". \n",
      "Debugged and modiﬁed \n",
      "Spark, HDFS, Makeﬁles, and YAML to \n",
      "enhance processing\n",
      "eﬃciency by \n",
      "25%\n",
      " and ensure seamless \n",
      "Cloudera integration\n",
      ". \n",
      "Streamlined workﬂows by managing \n",
      "data preparation, prediction, and monitoring\n",
      "scripts\n",
      ", ensuring accurate data access and processing. \n",
      "Designed and automated \n",
      "Jenkins-based CI/CD pipelines\n",
      ", reducing deployment time\n",
      "by \n",
      "40%\n",
      ". \n",
      "Deployed \n",
      "5+ ML models on BDH\n",
      ", processing \n",
      "10M+ transactions daily\n",
      " while reducing\n",
      "data processing costs by \n",
      "20%\n",
      ". \n",
      "Integrated \n",
      "AWS Lambda, AWS ECR, and SageMaker\n",
      " into model deployment\n",
      "workﬂows, improving scalability and automation. \n",
      "Technologies: \n",
      "Python, PySpark, Jenkins, Cloudera, HDFS, AWS, CI/CD Pipelines\n",
      ". \n",
      "Data Scientist \n",
      "Ielektron technologies Pvt. Ltd \n",
      "05/2022 - 05/2024\n",
      ", \n",
      " \n",
      "Pune \n",
      "Developed ML algorithms for \n",
      "ADAS (Advanced Driver Assistance Systems)\n",
      " using\n",
      "LIDAR & Radar datasets\n",
      ". \n",
      "Applied \n",
      "DBSCAN clustering, Decision Trees, and Gradient Boosting\n",
      " to improve\n",
      "vehicle classiﬁcation accuracy. \n",
      "Automated \n",
      "data pipelines using AWS\n",
      " to optimize real-time processing. \n",
      "Designed \n",
      "ML model testing pipelines\n",
      " \n",
      "for \n",
      "performance evaluation\n",
      " . \n",
      "Technologies: \n",
      "Python, AWS, Docker, PySpark, Pandas, NumPy\n",
      ". \n",
      "Quality Assurance Engineer \n",
      "KIDER INDIA PVT. LTD. / Pune \n",
      "02/2018 - 05/2022\n",
      ", \n",
      " \n",
      "Collected and analyzed \n",
      "staged production data\n",
      " to optimize factory operations. \n",
      "Detected and mitigated \n",
      "micro-outages\n",
      " that impacted production eﬃciency. \n",
      "Identiﬁed excessive energy consumption in key machines, optimizing the production\n",
      "line and increasing eﬃciency. \n",
      "EDUCATION \n",
      "Machine Learning & Deep Learning Certiﬁcation \n",
      "One Neuron \n",
      "Completed projects on \n",
      "ML models,\n",
      "Feature Engineering \n",
      "and\n",
      " Model\n",
      "Optimization\n",
      " \n",
      "Participated in \n",
      "Kaggle competitions\n",
      " \n",
      ",\n",
      "working on real-world ML problems. \n",
      "Bachelor of Engineering \n",
      "Dr. Rajendra Gode Institute of Technology & Research/Aamravti \n",
      "2013 - 2017\n",
      ", \n",
      " \n",
      "SKILLS \n",
      "Python \n",
      "Pyspark \n",
      "Pandas \n",
      "Numpy \n",
      "MLOps \n",
      "Docker for containerization \n",
      "Keras \n",
      "Scikit-learn \n",
      "Linux \n",
      "AWS \n",
      "Git Bash \n",
      "Shell script \n",
      "Spark \n",
      "HDFS \n",
      "Cloudera \n",
      "Jenkins \n",
      "Nexus \n",
      "Makeﬁle \n",
      "Jenkinsﬁle \n",
      "YAML \n",
      "Jira \n",
      "Vs code \n",
      "SQL \n",
      "Machine Learning \n",
      "Deep Learning \n",
      "Analytics and statistics \n",
      "Mathematics \n",
      "Data Exploration and Visualization \n",
      "PyCharm \n",
      "Data Visualization \n",
      "Data Warehouse \n",
      "ML Models deployments \n",
      "PROJECTS \n",
      "Capgemini Technology Services India Limited \n",
      "ML Model Migration for Banking Data\n",
      " \n",
      "Migrated and optimized ML models and ETL pipelines,\n",
      "transitioning from \n",
      "Cloudera to BDH\n",
      ". \n",
      "Debugged and reconﬁgured \n",
      "Spark, HDFS, and YAML\n",
      "catalogs\n",
      " for seamless data processing. \n",
      "Automated release management using \n",
      "Jenkins &\n",
      "Nexus\n",
      ", deploying models with real-time monitoring. \n",
      "Enhanced model performance by optimizing \n",
      "data\n",
      "preparation, predictions, and monitoring scripts\n",
      ". \n",
      "Ielektron Technologies Pvt. Ltd \n",
      "Advanced Driver Assistance Systems (ADAS)\n",
      " \n",
      "Developed \n",
      "object detection & classiﬁcation models\n",
      "for \n",
      "LIDAR & Radar data analysis\n",
      ". \n",
      "Implemented \n",
      "DBSCAN clustering & Gradient\n",
      "Boosting algorithms\n",
      " for accurate vehicle detection. \n",
      "Designed KPI evaluation scripts (MOT, RBE, EME, DET)\n",
      "to \n",
      "improve ADAS system accuracy\n",
      ". \n",
      "LANGUAGES \n",
      "English, Hindi, Marathi \n",
      "Elementary Proﬁciency \n",
      "Task \n",
      "Tasks \n",
      "Tasks \n",
      "Courses \n"
     ]
    }
   ],
   "source": [
    "# extract all text from pdf \n",
    "text=\"\"\n",
    "\n",
    "for page in pdf_reader.pages:\n",
    "    # print(page.extract_text())\n",
    "    text = text+page.extract_text()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a594cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shubham Karale \\nData Scientist \\nExperienced Data Scientist with \\n7 years of experience\\n, including \\n3 years specializing in Data Science & MLOps\\n.\\nCurrently at \\nCapgemini\\n, optimizing ML models and \\nmigrating SAS-based ETL pipelines to PySpark\\n, reducing model\\ninference time by \\n30%\\n and improving accuracy by \\n15%\\n. Proﬁcient in \\nPython, PySpark, Jenkins, Cloudera, AWS, and\\nML model testing\\n. Strong expertise in \\nfeature engineering, hyperparameter tuning, cloud deployment, and\\nMLOps pipelines\\n. Seeking to leverage expertise in data-driven solutions and cloud-based machine learning. \\nskarale63@gmail.com \\n+91 96896 49778 \\npune, India \\nlinkedin.com/in/shubham-karale-b343a7221 \\nWORK EXPERIENCE \\nData Scientist \\nCapgemini Technology Services India Limited \\n05/2024 - Present\\n, \\n \\nMigrated \\nSAS-based data pipelines\\n to \\nPySpark\\n, optimizing data extraction for ML\\nmodels. \\nExtracted only relevant features\\n from legacy SAS pipelines, reducing model\\ninference time by \\n30%',\n",
       " '30%\\n and improving accuracy by \\n15%\\n. \\nDebugged and modiﬁed \\nSpark, HDFS, Makeﬁles, and YAML to \\nenhance processing\\neﬃciency by \\n25%\\n and ensure seamless \\nCloudera integration\\n. \\nStreamlined workﬂows by managing \\ndata preparation, prediction, and monitoring\\nscripts\\n, ensuring accurate data access and processing. \\nDesigned and automated \\nJenkins-based CI/CD pipelines\\n, reducing deployment time\\nby \\n40%\\n. \\nDeployed \\n5+ ML models on BDH\\n, processing \\n10M+ transactions daily\\n while reducing\\ndata processing costs by \\n20%\\n. \\nIntegrated \\nAWS Lambda, AWS ECR, and SageMaker\\n into model deployment\\nworkﬂows, improving scalability and automation. \\nTechnologies: \\nPython, PySpark, Jenkins, Cloudera, HDFS, AWS, CI/CD Pipelines\\n. \\nData Scientist \\nIelektron technologies Pvt. Ltd \\n05/2022 - 05/2024\\n, \\n \\nPune \\nDeveloped ML algorithms for \\nADAS (Advanced Driver Assistance Systems)\\n using\\nLIDAR & Radar datasets\\n. \\nApplied \\nDBSCAN clustering, Decision Trees, and Gradient Boosting\\n to improve',\n",
       " 'to improve\\nvehicle classiﬁcation accuracy. \\nAutomated \\ndata pipelines using AWS\\n to optimize real-time processing. \\nDesigned \\nML model testing pipelines\\n \\nfor \\nperformance evaluation\\n . \\nTechnologies: \\nPython, AWS, Docker, PySpark, Pandas, NumPy\\n. \\nQuality Assurance Engineer \\nKIDER INDIA PVT. LTD. / Pune \\n02/2018 - 05/2022\\n, \\n \\nCollected and analyzed \\nstaged production data\\n to optimize factory operations. \\nDetected and mitigated \\nmicro-outages\\n that impacted production eﬃciency. \\nIdentiﬁed excessive energy consumption in key machines, optimizing the production\\nline and increasing eﬃciency. \\nEDUCATION \\nMachine Learning & Deep Learning Certiﬁcation \\nOne Neuron \\nCompleted projects on \\nML models,\\nFeature Engineering \\nand\\n Model\\nOptimization\\n \\nParticipated in \\nKaggle competitions\\n \\n,\\nworking on real-world ML problems. \\nBachelor of Engineering \\nDr. Rajendra Gode Institute of Technology & Research/Aamravti \\n2013 - 2017\\n, \\n \\nSKILLS \\nPython \\nPyspark \\nPandas \\nNumpy \\nMLOps',\n",
       " 'Numpy \\nMLOps \\nDocker for containerization \\nKeras \\nScikit-learn \\nLinux \\nAWS \\nGit Bash \\nShell script \\nSpark \\nHDFS \\nCloudera \\nJenkins \\nNexus \\nMakeﬁle \\nJenkinsﬁle \\nYAML \\nJira \\nVs code \\nSQL \\nMachine Learning \\nDeep Learning \\nAnalytics and statistics \\nMathematics \\nData Exploration and Visualization \\nPyCharm \\nData Visualization \\nData Warehouse \\nML Models deployments \\nPROJECTS \\nCapgemini Technology Services India Limited \\nML Model Migration for Banking Data\\n \\nMigrated and optimized ML models and ETL pipelines,\\ntransitioning from \\nCloudera to BDH\\n. \\nDebugged and reconﬁgured \\nSpark, HDFS, and YAML\\ncatalogs\\n for seamless data processing. \\nAutomated release management using \\nJenkins &\\nNexus\\n, deploying models with real-time monitoring. \\nEnhanced model performance by optimizing \\ndata\\npreparation, predictions, and monitoring scripts\\n. \\nIelektron Technologies Pvt. Ltd \\nAdvanced Driver Assistance Systems (ADAS)\\n \\nDeveloped \\nobject detection & classiﬁcation models\\nfor \\nLIDAR & Radar data analysis\\n.',\n",
       " '. \\nImplemented \\nDBSCAN clustering & Gradient\\nBoosting algorithms\\n for accurate vehicle detection. \\nDesigned KPI evaluation scripts (MOT, RBE, EME, DET)\\nto \\nimprove ADAS system accuracy\\n. \\nLANGUAGES \\nEnglish, Hindi, Marathi \\nElementary Proﬁciency \\nTask \\nTasks \\nTasks \\nCourses']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text convert into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "chunks = text_splitter.split_text(text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5486bb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S Karale\\AppData\\Local\\Temp\\ipykernel_7796\\3688893507.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1f26c3fc1a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply embedding and store in faiss\n",
    "embeddings = OllamaEmbeddings()\n",
    "vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e568821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S Karale\\AppData\\Local\\Temp\\ipykernel_7796\\1916815995.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm=Ollama()\n",
      "C:\\Users\\S Karale\\AppData\\Local\\Temp\\ipykernel_7796\\1916815995.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# use LLM model for chat\n",
    "llm=Ollama()\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages=True)\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=vector_store.as_retriever(), memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e25862f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6dfec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes user input and passes it to the LLM pipeline\n",
    "user_question = \"What is skill of shubham\"\n",
    "response = conversation_chain({'question': user_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d9e1556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is skill of shubham',\n",
       " 'chat_history': [HumanMessage(content='What is Name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Based on the provided context, I cannot determine the name of the person or organization mentioned. The text does not provide any clear clues or hints about the identity of the person or organization. Therefore, I'm afraid I cannot give you a helpful answer to this question.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is skill of shubham', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Based on the provided context, Shubham Karale's skills include:\\n\\n1. Python\\n2. PySpark\\n3. Pandas\\n4. NumPy\\n5. MLOps\\n6. Jenkins\\n7. Cloudera\\n8. AWS\\n9. Git Bash\\n10. Shell script\\n11. Spark\\n12. HDFS\\n13. Data Exploration and Visualization\\n14. PyCharm\\n15. Data Visualization\\n16. Data Warehouse\\n17. ML Models deployments\\n\\nShubham is proficient in these skills and has experience working with them in his professional projects.\", additional_kwargs={}, response_metadata={})],\n",
       " 'answer': \"Based on the provided context, Shubham Karale's skills include:\\n\\n1. Python\\n2. PySpark\\n3. Pandas\\n4. NumPy\\n5. MLOps\\n6. Jenkins\\n7. Cloudera\\n8. AWS\\n9. Git Bash\\n10. Shell script\\n11. Spark\\n12. HDFS\\n13. Data Exploration and Visualization\\n14. PyCharm\\n15. Data Visualization\\n16. Data Warehouse\\n17. ML Models deployments\\n\\nShubham is proficient in these skills and has experience working with them in his professional projects.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ca4ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is Name', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Based on the provided context, I cannot determine the name of the person or organization mentioned. The text does not provide any clear clues or hints about the identity of the person or organization. Therefore, I'm afraid I cannot give you a helpful answer to this question.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is skill of shubham', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Based on the provided context, Shubham Karale's skills include:\\n\\n1. Python\\n2. PySpark\\n3. Pandas\\n4. NumPy\\n5. MLOps\\n6. Jenkins\\n7. Cloudera\\n8. AWS\\n9. Git Bash\\n10. Shell script\\n11. Spark\\n12. HDFS\\n13. Data Exploration and Visualization\\n14. PyCharm\\n15. Data Visualization\\n16. Data Warehouse\\n17. ML Models deployments\\n\\nShubham is proficient in these skills and has experience working with them in his professional projects.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatHistory = response[\"chat_history\"]\n",
    "chatHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adedf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 content='What is Name' additional_kwargs={} response_metadata={}\n",
      "User:  What is Name\n",
      "1 content=\"Based on the provided context, I cannot determine the name of the person or organization mentioned. The text does not provide any clear clues or hints about the identity of the person or organization. Therefore, I'm afraid I cannot give you a helpful answer to this question.\" additional_kwargs={} response_metadata={}\n",
      "User:  Based on the provided context, I cannot determine the name of the person or organization mentioned. The text does not provide any clear clues or hints about the identity of the person or organization. Therefore, I'm afraid I cannot give you a helpful answer to this question.\n",
      "2 content='What is skill of shubham' additional_kwargs={} response_metadata={}\n",
      "User:  What is skill of shubham\n",
      "3 content=\"Based on the provided context, Shubham Karale's skills include:\\n\\n1. Python\\n2. PySpark\\n3. Pandas\\n4. NumPy\\n5. MLOps\\n6. Jenkins\\n7. Cloudera\\n8. AWS\\n9. Git Bash\\n10. Shell script\\n11. Spark\\n12. HDFS\\n13. Data Exploration and Visualization\\n14. PyCharm\\n15. Data Visualization\\n16. Data Warehouse\\n17. ML Models deployments\\n\\nShubham is proficient in these skills and has experience working with them in his professional projects.\" additional_kwargs={} response_metadata={}\n",
      "User:  Based on the provided context, Shubham Karale's skills include:\n",
      "\n",
      "1. Python\n",
      "2. PySpark\n",
      "3. Pandas\n",
      "4. NumPy\n",
      "5. MLOps\n",
      "6. Jenkins\n",
      "7. Cloudera\n",
      "8. AWS\n",
      "9. Git Bash\n",
      "10. Shell script\n",
      "11. Spark\n",
      "12. HDFS\n",
      "13. Data Exploration and Visualization\n",
      "14. PyCharm\n",
      "15. Data Visualization\n",
      "16. Data Warehouse\n",
      "17. ML Models deployments\n",
      "\n",
      "Shubham is proficient in these skills and has experience working with them in his professional projects.\n"
     ]
    }
   ],
   "source": [
    "# chat history of QaN\n",
    "for i, message in enumerate(chatHistory):\n",
    "    print(i, message)\n",
    "    if i%2 == 0:\n",
    "        print(f\"User:  {message.content}\")\n",
    "    else:\n",
    "        print(f\"Reply:  {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50c18e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': ['What is Name', 'What is skill of shubham'],\n",
       " 'Answer': [\"Based on the provided context, I cannot determine the name of the person or organization mentioned. The text does not provide any clear clues or hints about the identity of the person or organization. Therefore, I'm afraid I cannot give you a helpful answer to this question.\",\n",
       "  \"Based on the provided context, Shubham Karale's skills include:\\n\\n1. Python\\n2. PySpark\\n3. Pandas\\n4. NumPy\\n5. MLOps\\n6. Jenkins\\n7. Cloudera\\n8. AWS\\n9. Git Bash\\n10. Shell script\\n11. Spark\\n12. HDFS\\n13. Data Exploration and Visualization\\n14. PyCharm\\n15. Data Visualization\\n16. Data Warehouse\\n17. ML Models deployments\\n\\nShubham is proficient in these skills and has experience working with them in his professional projects.\"]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save chart history in dict formate\n",
    "\n",
    "question = []\n",
    "answer = []\n",
    "\n",
    "for i, message in enumerate(chatHistory):\n",
    "    if i%2 == 0:\n",
    "        question.append(message.content)\n",
    "    else:\n",
    "        answer.append(message.content)\n",
    "\n",
    "qa_pairs = {\"Question\": question, \"Answer\": answer}\n",
    "\n",
    "qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d38c264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into dataframe\n",
    "df = pd.DataFrame(qa_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f2c41fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Name</td>\n",
       "      <td>Based on the provided context, I cannot determ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is skill of shubham</td>\n",
       "      <td>Based on the provided context, Shubham Karale'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Question                                             Answer\n",
       "0              What is Name  Based on the provided context, I cannot determ...\n",
       "1  What is skill of shubham  Based on the provided context, Shubham Karale'..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacving to csv formate\n",
    "csv_path = Path(r\"D:\\SHUBHAM\\git_repo\\ask-your-pdf\\notebook\\qa_history.csv\")\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610fe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
